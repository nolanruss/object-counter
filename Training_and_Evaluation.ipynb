{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers.core import Dense\n",
    "from keras.optimizers import Adam\n",
    "from keras.initializers import Constant\n",
    "from keras.layers import Add, Activation\n",
    "from keras.layers.convolutional import Conv2D, Conv2DTranspose, MaxPooling2D, UpSampling2D\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from keras.models import Input, Model\n",
    "from keras.applications.vgg16 import VGG16\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import keras\n",
    "from losses import binary_cross\n",
    "import keras.backend as K\n",
    "import metrics\n",
    "from dataset import quick_dataset, load_images, normalize, per_chan_avg, apply_masks\n",
    "from cv2 import bitwise_and\n",
    "import nn_models\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline experiments\n",
    "Goal: To evaluate how well the network performs when trained to count.  Hypothesis is that the counting pipeline will perform the best on images which are more sparsely populated, and will count better using the segmented images.\n",
    "The following conditions\n",
    "* Small cells\n",
    "* Large cells\n",
    "\n",
    "Compare the following\n",
    "* Segmentation quality\n",
    "* Plaque counts\n",
    "\n",
    "We are comparing 3 neural networks\n",
    "1. Segmentation network trained on small cells\n",
    "2. Segmentation network trained on large cells\n",
    "3. Segmentation network trained on both large and small cells\n",
    "* Compare mean IoU\n",
    "\n",
    "Counting Comparison\n",
    "1. Count network trained using cells isolated from original images (using the segmentation network with the best mean IoU)\n",
    "2. Count network trained using the segmented images (training with the blobs instead of isolated cells)\n",
    "* Compare the counts achieved by comparing:\n",
    "    * Plot the counts, mean, and standard deviations\n",
    "    * Evaluation of counts with mean, and standard deviation, for the individual counts\n",
    "    * Identify a threshold, see if counting is better/worse at higher or lower counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the datasets\n",
    "* Set 1: Small cells (training set [0:480], Validation set [0:120])\n",
    "* Set 2: large cells (training set [480:960], Validation set [120:])\n",
    "* Set 3: Combined cells set(training set[0:], validation set [0:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get the filename metadata and set the paths of the images and ground truth files\n",
    "train_meta = pd.read_csv('training_set.csv')\n",
    "val_meta = pd.read_csv('validation_set.csv')\n",
    "gt_path = './BBBC005_v1_ground_truth'\n",
    "img_path = './BBBC005_v1_images'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get the small images for a dataset\n",
    "tx_sm = load_images(img_names=train_meta.filename[:480], file_path=img_path, preprocess='image', target_size=(224,224,3))\n",
    "ty_sm  = load_images(img_names=train_meta.filename[:480], file_path=gt_path, preprocess='gt', target_size=(224,224))\n",
    "vx_sm = load_images(img_names=val_meta.filename[:120], file_path=img_path, preprocess='image', target_size=(224,224,3))\n",
    "vy_sm = load_images(img_names=val_meta.filename[:120], file_path=gt_path, preprocess='gt', target_size=(224,224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get the large images for a dataset\n",
    "tx_lg = load_images(img_names=train_meta.filename[480:], file_path=img_path, preprocess='image', target_size=(224,224,3))\n",
    "ty_lg  = load_images(img_names=train_meta.filename[480:], file_path=gt_path, preprocess='gt', target_size=(224,224))\n",
    "vx_lg = load_images(img_names=val_meta.filename[120:], file_path=img_path, preprocess='image', target_size=(224,224,3))\n",
    "vy_lg = load_images(img_names=val_meta.filename[120:], file_path=gt_path, preprocess='gt', target_size=(224,224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get both the large and small images for a dataset\n",
    "tx_full = load_images(img_names=train_meta.filename[0:], file_path=img_path, preprocess='image', target_size=(224,224,3))\n",
    "ty_full  = load_images(img_names=train_meta.filename[0:], file_path=gt_path, preprocess='gt', target_size=(224,224))\n",
    "vx_full = load_images(img_names=val_meta.filename[0:], file_path=img_path, preprocess='image', target_size=(224,224,3))\n",
    "vy_full = load_images(img_names=val_meta.filename[0:], file_path=gt_path, preprocess='gt', target_size=(224,224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_counts(filenames):\n",
    "    count = []\n",
    "    for f in filenames:\n",
    "        count.append(int(str.split(str.split(f, '_')[2], 'C')[1]))\n",
    "    return count\n",
    "train_counts_sm = get_counts(train_meta.filename[:480])\n",
    "val_counts_sm = get_counts(val_meta.filename[:120])\n",
    "train_counts_lg = get_counts(train_meta.filename[480:])\n",
    "val_counts_lg = get_counts(val_meta.filename[120:])\n",
    "train_counts_full = get_counts(train_meta.filename)\n",
    "val_counts_full = get_counts(val_meta.filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Normalize the small datasets\n",
    "avgs = per_chan_avg(tx_sm)\n",
    "normalize(tx_sm, avgs)\n",
    "normalize(vx_sm, avgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Normalize the large datasets\n",
    "avgs = per_chan_avg(tx_lg)\n",
    "normalize(tx_lg, avgs)\n",
    "normalize(vx_lg, avgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Normalize the full datasets\n",
    "avgs = per_chan_avg(tx_full)\n",
    "normalize(tx_full, avgs)\n",
    "normalize(vx_full, avgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "im_num = -1\n",
    "fig, a = plt.subplots(1, 6)\n",
    "a[0].imshow(tx_sm[im_num,:,:,2])\n",
    "a[1].imshow(ty_sm[im_num,:,:,0])\n",
    "a[2].imshow(tx_lg[im_num,:,:,2])\n",
    "a[3].imshow(ty_lg[im_num,:,:,0])\n",
    "a[4].imshow(tx_full[im_num,:,:,2])\n",
    "a[5].imshow(ty_full[im_num,:,:,0])\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(18.5, 10.5)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segmentation (Blob Detection) Network Comparison\n",
    "#### Train the network on the small cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fcn_sm = nn_models.build_fcn_bilinear_8s(nb_classes=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NB_EPOCHS = 1000\n",
    "OPTIMIZER = Adam(lr=0.001)\n",
    "LOSS = binary_cross # Binary cross entropy\n",
    "VERBOSE = 1\n",
    "BATCH_SIZE = 1\n",
    "\n",
    "# Create a callback function to save the most accurate version of our model following each epoch, to stop if learning stops, and\n",
    "# to reduce the learning rate if loss fails to decrease.\n",
    "CALLBACKS = [ModelCheckpoint('mod/fcn8s_weights_sm.hdf5', monitor='loss', verbose=1, \n",
    "                           save_best_only=True, save_weights_only=False, mode='auto', period=1),\n",
    "            EarlyStopping(monitor='loss', min_delta=0, patience=15, verbose=0, mode='auto'),\n",
    "            ReduceLROnPlateau(monitor='loss', factor=0.1, patience=10, verbose=VERBOSE, mode='auto',\n",
    "                              epsilon=0.0001, cooldown=0, min_lr=0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fcn_sm.compile(loss=LOSS, optimizer=OPTIMIZER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sm_history = fcn_sm.fit(x=tx_sm,y=ty_sm, epochs=NB_EPOCHS, batch_size=BATCH_SIZE, verbose=VERBOSE, callbacks=CALLBACKS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fcn_sm = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the network on large cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fcn_lg = nn_models.build_fcn_bilinear_8s(nb_classes=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NB_EPOCHS = 1000\n",
    "OPTIMIZER = Adam(lr=0.001)\n",
    "LOSS = binary_cross # Binary cross entropy\n",
    "VERBOSE = 1\n",
    "BATCH_SIZE = 1\n",
    "\n",
    "# Create a callback function to save the most accurate version of our model following each epoch, to stop if learning stops, and\n",
    "# to reduce the learning rate if loss fails to decrease.\n",
    "CALLBACKS = [ModelCheckpoint('mod/fcn8s_weights_lg.hdf5', monitor='loss', verbose=1, \n",
    "                           save_best_only=True, save_weights_only=False, mode='auto', period=1),\n",
    "            EarlyStopping(monitor='loss', min_delta=0, patience=15, verbose=0, mode='auto'),\n",
    "            ReduceLROnPlateau(monitor='loss', factor=0.1, patience=10, verbose=VERBOSE, mode='auto',\n",
    "                              epsilon=0.0001, cooldown=0, min_lr=0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fcn_lg.compile(loss=LOSS, optimizer=OPTIMIZER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lg_history = fcn_lg.fit(x=tx_lg,y=ty_lg, epochs=NB_EPOCHS, batch_size=BATCH_SIZE, verbose=VERBOSE, callbacks=CALLBACKS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fcn_lg = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the network on the full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fcn_full = nn_models.build_fcn_bilinear_8s(nb_classes=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NB_EPOCHS = 1000\n",
    "OPTIMIZER = Adam(lr=0.001)\n",
    "LOSS = binary_cross # Binary cross entropy\n",
    "VERBOSE = 1\n",
    "BATCH_SIZE = 1\n",
    "\n",
    "# Create a callback function to save the most accurate version of our model following each epoch, to stop if learning stops, and\n",
    "# to reduce the learning rate if loss fails to decrease.\n",
    "CALLBACKS = [ModelCheckpoint('mod/fcn8s_weights_full.hdf5', monitor='loss', verbose=1, \n",
    "                           save_best_only=True, save_weights_only=False, mode='auto', period=1),\n",
    "            EarlyStopping(monitor='loss', min_delta=0, patience=15, verbose=0, mode='auto'),\n",
    "            ReduceLROnPlateau(monitor='loss', factor=0.1, patience=10, verbose=VERBOSE, mode='auto',\n",
    "                              epsilon=0.0001, cooldown=0, min_lr=0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fcn_full.compile(loss=LOSS, optimizer=OPTIMIZER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "full_history = fcn_full.fit(x=tx_full,y=ty_full, epochs=NB_EPOCHS, batch_size=BATCH_SIZE, verbose=VERBOSE, callbacks=CALLBACKS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fcn_full = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Segmentation Results Comparison\n",
    "Results are evaluated through mean IoU comparison.  This will happen by first determining the optimial threshold for each set of data, and then determining the mean IoU for the data on which the network was trained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Generate a set of thresholds to evaluate, between 0 and 1\n",
    "xRange = np.array(range(100), dtype=np.float32)\n",
    "xRange += 1\n",
    "xRange /= 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Get the small network optimal threshold\n",
    "fcn_sm = nn_models.build_fcn_bilinear_8s(nb_classes=1)\n",
    "fcn_sm.load_weights('mod/fcn8s_weights_sm.hdf5')\n",
    "sm_preds = fcn_sm.predict(vx_sm)\n",
    "\n",
    "# Get the mean IoU and plot\n",
    "meanIoU_by_thresh = metrics.meanIoU_thresholds(sm_preds, vy_sm)\n",
    "fig = plt.figure(figsize=(8, 6))\n",
    "plt.scatter(xRange, meanIoU_by_thresh)\n",
    "plt.title('Small Cell Dataset Mean IoU vs. Threshold Value')\n",
    "plt.ylabel('Mean IoU')\n",
    "plt.xlabel('Threshold')\n",
    "\n",
    "# Get the optimal threshold, print the results\n",
    "sm_thresh = xRange[np.argmax(meanIoU_by_thresh)]\n",
    "sm_meanIoU = np.amax(meanIoU_by_thresh)\n",
    "print('Max IoU',np.amax(meanIoU_by_thresh), 'Optimal IoU Threshold',xRange[np.argmax(meanIoU_by_thresh)])\n",
    "fcn_sm = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Get the large network optimal threshold\n",
    "fcn_lg = nn_models.build_fcn_bilinear_8s(nb_classes=1)\n",
    "fcn_lg.load_weights('mod/fcn8s_weights_lg.hdf5')\n",
    "lg_preds = fcn_lg.predict(vx_lg)\n",
    "\n",
    "# Get the mean IoU and plot\n",
    "meanIoU_by_thresh = metrics.meanIoU_thresholds(lg_preds, vy_lg)\n",
    "fig = plt.figure(figsize=(8, 6))\n",
    "plt.scatter(xRange, meanIoU_by_thresh)\n",
    "plt.title('Large Cell Dataset Mean IoU vs. Threshold Value')\n",
    "plt.ylabel('Mean IoU')\n",
    "plt.xlabel('Threshold')\n",
    "lg_thresh = xRange[np.argmax(meanIoU_by_thresh)]\n",
    "lg_meanIoU = np.amax(meanIoU_by_thresh)\n",
    "print('Max IoU',np.amax(meanIoU_by_thresh), 'Optimal IoU Threshold',xRange[np.argmax(meanIoU_by_thresh)])\n",
    "#fcn_lg = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Get the large network optimal threshold\n",
    "fcn_full = nn_models.build_fcn_bilinear_8s(nb_classes=1)\n",
    "fcn_full.load_weights('mod/fcn8s_weights_full.hdf5')\n",
    "full_preds = fcn_full.predict(vx_full)\n",
    "\n",
    "# Get the mean IoU and plot\n",
    "meanIoU_by_thresh = metrics.meanIoU_thresholds(full_preds, vy_full)\n",
    "fig = plt.figure(figsize=(8, 6))\n",
    "plt.scatter(xRange, meanIoU_by_thresh)\n",
    "plt.title('Full Cell Dataset Mean IoU vs. Threshold Value')\n",
    "plt.ylabel('Mean IoU')\n",
    "plt.xlabel('Threshold')\n",
    "\n",
    "# Get the optimal threshold, print the results\n",
    "full_thresh = xRange[np.argmax(meanIoU_by_thresh)]\n",
    "full_meanIoU = np.amax(meanIoU_by_thresh)\n",
    "print('Max IoU',np.amax(meanIoU_by_thresh), 'Optimal IoU Threshold',xRange[np.argmax(meanIoU_by_thresh)])\n",
    "fcn_full = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compare the mean IoU achieved for each dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "meanIoUs = np.array((sm_meanIoU, lg_meanIoU, full_meanIoU))\n",
    "fig, ax = plt.subplots()\n",
    "ind = np.arange(1, 4)\n",
    "sm, lg, full = plt.bar((1, 2, 3), meanIoUs)\n",
    "plt.title('Mean Intersection Over Union')\n",
    "sm.set_facecolor('r')\n",
    "lg.set_facecolor('b')\n",
    "full.set_facecolor('rebeccapurple')\n",
    "ax.set_xticks(np.arange(1, 4))\n",
    "ax.set_xticklabels(['Small Cells', 'Large Cells', 'Combined\\nLarge/Small'])\n",
    "ax.set_ylim([0, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count Network Training and Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create 3 datasets\n",
    "1. The prediction image\n",
    "2. The predictions with a threshold applied\n",
    "3. The original image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# ID the high-performing model, and then train the counters\n",
    "if (sm_meanIoU > lg_meanIoU) and (sm_meanIoU > full_meanIoU):\n",
    "    print('Loading small cell blob detector')\n",
    "    fcn = nn_models.build_fcn_bilinear_8s(nb_classes=1)\n",
    "    fcn.load_weights('mod/fcn8s_weights_lg.hdf5')\n",
    "    seg_preds = fcn.predict(tx_lg)\n",
    "    im_preds = tx_lg\n",
    "    train_counts = train_counts_lg\n",
    "    val_counts = val_counts_lg\n",
    "    thresh = sm_thresh\n",
    "elif (lg_meanIoU > sm_meanIoU) and (lg_meanIoU > full_meanIoU):\n",
    "    print('Loading large cell blob detector')\n",
    "    fcn = nn_models.build_fcn_bilinear_8s(nb_classes=1)\n",
    "    fcn.load_weights('mod/fcn8s_weights_lg.hdf5')\n",
    "    seg_preds = fcn.predict(tx_lg)\n",
    "    im_preds = tx_lg\n",
    "    train_counts = train_counts_lg\n",
    "    val_counts = val_counts_lg\n",
    "    thresh = lg_thresh\n",
    "else:\n",
    "    print('Loading large/small combo cell blob detector')\n",
    "    fcn = nn_models.build_fcn_bilinear_8s(nb_classes=1)\n",
    "    fcn.load_weights('mod/fcn8s_weights_full.hdf5')\n",
    "    seg_preds = fcn.predict(tx_full)\n",
    "    im_preds = tx_full\n",
    "    train_counts = train_counts_full\n",
    "    val_counts = val_counts_full\n",
    "    thresh = full_thresh\n",
    "print('Threshold',thresh)\n",
    "plt.imshow(seg_preds[15,:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Generate a set of thresholds to evaluate, between 0 and 1\n",
    "xRange = np.array(range(100), dtype=np.float32)\n",
    "xRange += 1\n",
    "xRange /= 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    fcn = nn_models.build_fcn_bilinear_8s(nb_classes=1)\n",
    "    fcn.load_weights('mod/fcn8s_weights_lg.hdf5')\n",
    "    lg_preds = fcn.predict(vx_lg)\n",
    "     # Get the mean IoU and plot\n",
    "    meanIoU_by_thresh = metrics.meanIoU_thresholds(lg_preds, vy_lg)\n",
    "    fig = plt.figure(figsize=(8, 6))\n",
    "    plt.scatter(xRange, meanIoU_by_thresh)\n",
    "    plt.title('Large Cell Dataset Mean IoU vs. Threshold Value')\n",
    "    plt.ylabel('Mean IoU')\n",
    "    plt.xlabel('Threshold')\n",
    "    lg_thresh = xRange[np.argmax(meanIoU_by_thresh)]\n",
    "    lg_meanIoU = np.amax(meanIoU_by_thresh)\n",
    "    print('Max IoU',np.amax(meanIoU_by_thresh), 'Optimal IoU Threshold',xRange[np.argmax(meanIoU_by_thresh)])\n",
    "    seg_preds = fcn.predict(tx_lg)\n",
    "    im_preds = tx_lg\n",
    "    train_counts = train_counts_lg\n",
    "    val_counts = val_counts_lg\n",
    "    thresh = lg_thresh\n",
    "    fcn = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process the blob predictions for training the segmentation (blob) counter\n",
    "Prep the data to be trained using only the blob predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Form the dataset to have 3 data channels by concatenating the blob predictions\n",
    "seg_preds = np.concatenate((seg_preds, seg_preds, seg_preds), axis=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seg_preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Apply the optimal threshold to the blobs, convert them to the standard image scale of 255, and then normalize the data\n",
    "seg_preds_thresh = np.array((seg_preds > thresh) * 255, dtype=np.float32)\n",
    "avgs = per_chan_avg(arr=seg_preds_thresh)\n",
    "normalize(arr=seg_preds_thresh, avgs=avgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Apply the optimal threshold to the blobs without a threshold, convert them to the standard image scale of 255, and then normalize the data\n",
    "seg_preds_nt = np.array(seg_preds * 255, dtype=np.float32)\n",
    "avgs_nt = per_chan_avg(arr=seg_preds_nt)\n",
    "normalize(arr=seg_preds_nt, avgs=avgs_nt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the blob predictions to isolate cells from the original images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get the original large images for our dataset\n",
    "tx_lg = load_images(img_names=train_meta.filename[480:], file_path=img_path, preprocess='image', target_size=(224,224,3))\n",
    "ty_lg  = load_images(img_names=train_meta.filename[480:], file_path=gt_path, preprocess='gt', target_size=(224,224))\n",
    "vx_lg = load_images(img_names=val_meta.filename[120:], file_path=img_path, preprocess='image', target_size=(224,224,3))\n",
    "vy_lg = load_images(img_names=val_meta.filename[120:], file_path=gt_path, preprocess='gt', target_size=(224,224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Apply the optimal threshold to the blobs, and then use them as masks to isolate cells from the original images\n",
    "masks = np.array((seg_preds > thresh), dtype=np.float32)\n",
    "iso_preds = apply_masks(tx_lg, masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Normalize the masked Data\n",
    "avgs = per_chan_avg(arr=iso_preds)\n",
    "normalize(arr=iso_preds, avgs=avgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(iso_preds[100,:,:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Counting Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the segmentation counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seg_counter = nn_models.build_count_nn(nb_classes=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CALLBACKS = [ModelCheckpoint('mod/seg_counter.hdf5', monitor='mean_absolute_error', verbose=1, \n",
    "                           save_best_only=True, save_weights_only=True, mode='auto', period=1),\n",
    "            ReduceLROnPlateau(monitor='loss', factor=0.1, patience=10, verbose=1, mode='auto',\n",
    "                              epsilon=0.0001, cooldown=0, min_lr=0),\n",
    "            keras.callbacks.EarlyStopping(monitor='loss', min_delta=0, patience=30, verbose=0, mode='auto')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seg_counter.compile(optimizer='Adam',\n",
    "                     loss='mean_squared_error',\n",
    "                     metrics=['mean_absolute_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "seg_history = seg_counter.fit(seg_preds_thresh, train_counts,\n",
    "                          epochs=1000,\n",
    "                          batch_size=40,\n",
    "                          callbacks=CALLBACKS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Close the trained counter\n",
    "seg_counter = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Segmentation Counter, no threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "seg_history = seg_counter.fit(seg_preds, train_counts,\n",
    "                          epochs=1000,\n",
    "                          batch_size=40,\n",
    "                          callbacks=CALLBACKS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seg_preds = fcn.predict(seg_preds_nt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seg_preds = np.concatenate((seg_preds, seg_preds, seg_preds), axis=3)\n",
    "# Apply threshold\n",
    "seg_preds = np.array((seg_preds * 255), dtype=np.float32)\n",
    "avgs = per_chan_avg(arr=seg_preds)\n",
    "normalize(arr=seg_preds, avgs=avgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seg_counter_nt = nn_models.build_count_nn(nb_classes=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seg_counter_nt.load_weights('mod/seg_counter.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CALLBACKS = [ModelCheckpoint('mod/seg_counter_nt.hdf5', monitor='mean_absolute_error', verbose=1, \n",
    "                           save_best_only=True, save_weights_only=True, mode='auto', period=1),\n",
    "            ReduceLROnPlateau(monitor='loss', factor=0.1, patience=10, verbose=1, mode='auto',\n",
    "                              epsilon=0.0001, cooldown=0, min_lr=0),\n",
    "            keras.callbacks.EarlyStopping(monitor='loss', min_delta=0, patience=30, verbose=0, mode='auto')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seg_counter_nt.compile(optimizer='Adam',\n",
    "                     loss='mean_squared_error',\n",
    "                     metrics=['mean_absolute_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "seg_history_nt = seg_counter_nt.fit(seg_preds, train_counts,\n",
    "                          epochs=1000,\n",
    "                          batch_size=40,\n",
    "                          callbacks=CALLBACKS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the isolated blob image Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_counter = nn_models.build_count_nn(nb_classes=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_counter.load_weights('mod/iso_counter.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CALLBACKS = [ModelCheckpoint('mod/iso_counter.hdf5', monitor='mean_absolute_error', verbose=1, \n",
    "                           save_best_only=True, save_weights_only=True, mode='auto', period=1),\n",
    "            ReduceLROnPlateau(monitor='loss', factor=0.1, patience=10, verbose=1, mode='auto',\n",
    "                              epsilon=0.0001, cooldown=0, min_lr=0),\n",
    "            keras.callbacks.EarlyStopping(monitor='mean_absolute_error', min_delta=0, patience=30, verbose=0, mode='auto')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_counter.compile(optimizer='Adam',\n",
    "                     loss='mean_squared_error',\n",
    "                     metrics=['mean_absolute_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "img_history = img_counter.fit(iso_preds, train_counts,\n",
    "                          epochs=1000,\n",
    "                          batch_size=40,\n",
    "                          callbacks=CALLBACKS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Counting Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtain counts from the models for the validation sets and compare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start with the segmentation (blob detection) network counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Normalize the validation image set\n",
    "vx_normal = vx_lg\n",
    "avgs = per_chan_avg(vx_normal)\n",
    "normalize(arr=vx_normal, avgs=avgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seg_counter = nn_models.build_count_nn(nb_classes=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seg_counter.load_weights('mod/seg_counter.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Obtain the blob predictions for the validation dataset\n",
    "seg_vx_lg = fcn.predict(vx_normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seg_vx_lg = np.concatenate((seg_vx_lg,seg_vx_lg,seg_vx_lg), axis=3)\n",
    "# Apply the optimal threshold to the blobs, convert them to the standard image scale of 255, and then normalize the data\n",
    "seg_vx_lg = np.array((seg_vx_lg > thresh) * 255, dtype=np.float32)\n",
    "avgs = per_chan_avg(arr=seg_vx_lg)\n",
    "normalize(arr=seg_vx_lg, avgs=avgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seg_vx_counts = seg_counter.predict(seg_vx_lg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seg_dat = pd.DataFrame({'Count': val_counts,\n",
    "                   'Pred': seg_vx_counts[:,0]})\n",
    "#Group the data by count\n",
    "seg_grouped = seg_dat.groupby('Count')\n",
    "seg_dat_1sig = seg_grouped.std()\n",
    "seg_dat_2sig = seg_dat_1sig * 2\n",
    "seg_dat_mean = seg_grouped.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seg_dat.to_csv('data/segmented_counts.csv')\n",
    "seg_grouped.to_csv('data/segmented_counts_grouped.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Segmentation counting without threshold\n",
    "Test the count of the segmentation (blobs) without a threshold applied counting results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seg_nt_vx_lg = fcn.predict(vx_normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seg_nt_vx_lg = np.concatenate((seg_nt_vx_lg,seg_nt_vx_lg,seg_nt_vx_lg), axis=3)\n",
    "# Scale the predictions to the pixel scale 255, and then normalize the data\n",
    "seg_nt_vx_lg = np.array(seg_nt_vx_lg * 255, dtype=np.float32)\n",
    "avgs = per_chan_avg(arr=seg_nt_vx_lg)\n",
    "normalize(arr=seg_nt_vx_lg, avgs=avgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seg_counter_nt = nn_models.build_count_nn(nb_classes=1)\n",
    "seg_counter_nt.load_weights('mod/seg_counter_nt.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seg_nt_vx_counts = seg_counter_nt.predict(seg_nt_vx_lg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seg_nt_dat = pd.DataFrame({'Count': val_counts,\n",
    "                   'Pred': seg_nt_vx_counts[:,0]})\n",
    "#Group the data by count\n",
    "seg_nt_grouped = seg_nt_dat.groupby('Count')\n",
    "seg_nt_dat_1sig = seg_nt_grouped.std()\n",
    "seg_nt_dat_2sig = seg_nt_dat_1sig * 2\n",
    "seg_nt_dat_mean = seg_nt_grouped.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seg_nt_dat.to_csv('data/segmented_nt_counts.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Isolated images\n",
    "Test the results for the isolated blob counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fcn = nn_models.build_fcn_bilinear_8s(nb_classes=1)\n",
    "fcn.load_weights('mod/fcn8s_weights_lg.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "iso_vx = fcn.predict(vx_normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "iso_vx = np.concatenate((iso_vx,iso_vx,iso_vx), axis=3)\n",
    "# Apply the optimal threshold to the blobs, and then use them as masks to isolate cells from the original images\n",
    "masks = np.array((iso_vx > thresh), dtype=np.float32)\n",
    "iso_preds = apply_masks(vx_lg, masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Normalize the masked Data\n",
    "avgs = per_chan_avg(arr=iso_preds)\n",
    "normalize(arr=iso_preds, avgs=avgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(iso_preds[6,:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_counter = nn_models.build_count_nn(nb_classes=1)\n",
    "img_counter.load_weights('mod/iso_counter.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_vx_counts = img_counter.predict(iso_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_dat = pd.DataFrame({'Count': val_counts,\n",
    "                   'Pred': img_vx_counts[:,0]})\n",
    "#Group the data by count\n",
    "img_grouped = img_dat.groupby('Count')\n",
    "img_dat_1sig = img_grouped.std()\n",
    "img_dat_2sig = img_dat_1sig * 2\n",
    "img_dat_mean = img_grouped.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_dat.to_csv('data/iso_counts.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare the counting results\n",
    "Perform the Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def scatter_with_deviation(val_counts, reg_val_preds, grouped, title):\n",
    "    plt.figure(figsize=(8,5))\n",
    "    plt.scatter(val_counts, reg_val_preds, marker=\".\")\n",
    "    plt.plot(grouped.mean())\n",
    "    plt.plot((np.array(range(100)) + 1))\n",
    "    plt.ylabel('Prediction')\n",
    "    plt.xlabel('Cell Count')\n",
    "    plt.title(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scatter_with_deviation(val_counts, seg_vx_counts, seg_grouped, 'Predictions from Segmented Image w/Threshold vs. Actual Counts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scatter_with_deviation(val_counts, img_vx_counts, img_grouped,'Predictions from Isolated Blob Images vs. Actual Counts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scatter_with_deviation(val_counts, seg_nt_vx_counts, seg_nt_grouped, 'Predictions from Segmented Image w/o Threshold vs. Actual Counts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seg_nt_gp = pd.DataFrame(seg_nt_grouped.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.plot(seg_nt_gp.index, seg_nt_grouped.std())\n",
    "plt.scatter(seg_nt_gp.index, seg_grouped.std())\n",
    "plt.scatter(seg_nt_gp.index, img_grouped.std())\n",
    "plt.title('Prediction Standard Deviations vs. Actual Counts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = seg_nt_grouped['Count'].all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = x.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Three subplots sharing both x/y axes\n",
    "f, (ax1, ax2, ax3) = plt.subplots(3, sharex=True, sharey=True)\n",
    "ax1.plot(seg_nt_gp.index, seg_nt_grouped.std())\n",
    "ax1.set_title('Standard Deviation vs. Cell Count')\n",
    "ax2.plot(seg_nt_gp.index, seg_grouped.std())\n",
    "ax3.plot(seg_nt_gp.index, img_grouped.std(), color='r')\n",
    "# Fine-tune figure; make subplots close to each other and hide x ticks for\n",
    "# all but bottom plot.\n",
    "f.subplots_adjust(hspace=0)\n",
    "plt.setp([a.get_xticklabels() for a in f.axes[:-1]], visible=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
