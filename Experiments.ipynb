{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers.core import Dense\n",
    "from keras.optimizers import Adam\n",
    "from keras.initializers import Constant\n",
    "from keras.layers import Add, Activation\n",
    "from keras.layers.convolutional import Conv2D, Conv2DTranspose, MaxPooling2D, UpSampling2D\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from keras.models import Input, Model\n",
    "from keras.applications.vgg16 import VGG16\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import keras\n",
    "from losses import binary_cross\n",
    "import keras.backend as K\n",
    "import metrics\n",
    "from dataset import quick_dataset, load_images, normalize, per_chan_avg\n",
    "import nn_models\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline experiments\n",
    "Goal: To evaluate how well the network performs when trained to count.  Hypothesis is that the counting pipeline will perform the best on images which are more sparsely populated, and will count better using the segmented images.\n",
    "The following conditions\n",
    "* Small cells\n",
    "* Large cells\n",
    "\n",
    "Compare the following\n",
    "* Segmentation quality\n",
    "* Plaque counts\n",
    "\n",
    "We are comparing 2(3?) neural networks\n",
    "1. Segmentation network trained on small cells\n",
    "2. Segmentation network trained on large cells\n",
    "* Compare mean IoU\n",
    "\n",
    "Counting Comparison\n",
    "1. Count network trained using original images (based on the images of the segmentation network with the best mean IoU)\n",
    "2. Count network trained using the segmented images (used to train the segmentation network)\n",
    "* Compare the counts achieved by comparing:\n",
    "    * Plot the counts, mean, and standard deviations\n",
    "    * Average standard deviation\n",
    "    * Evaluation of counts with mean, and standard deviation, for the individual counts\n",
    "        * Identify a threshold, see if counting is better/worse at higher or lower counts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the datasets\n",
    "* Set 1: Small cells (training set [0:480], Validation set [0:120])\n",
    "* Set 2: large cells (training set [480:960], Validation set [0:120])\n",
    "* Set 3: Combined cells set(training set[0:], validation set [0:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get the filename metadata and set the paths of the images and ground truth files\n",
    "train_meta = pd.read_csv('training_set.csv')\n",
    "val_meta = pd.read_csv('validation_set.csv')\n",
    "gt_path = './BBBC005_v1_ground_truth'\n",
    "img_path = './BBBC005_v1_images'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get the small images for a dataset\n",
    "tx_sm = load_images(img_names=train_meta.filename[:480], file_path=img_path, preprocess='image', target_size=(224,224,3))\n",
    "ty_sm  = load_images(img_names=train_meta.filename[:480], file_path=gt_path, preprocess='gt', target_size=(224,224))\n",
    "vx_sm = load_images(img_names=val_meta.filename[:120], file_path=img_path, preprocess='image', target_size=(224,224,3))\n",
    "vy_sm = load_images(img_names=val_meta.filename[:120], file_path=gt_path, preprocess='gt', target_size=(224,224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get the small images for a dataset\n",
    "tx_lg = load_images(img_names=train_meta.filename[480:], file_path=img_path, preprocess='image', target_size=(224,224,3))\n",
    "ty_lg  = load_images(img_names=train_meta.filename[480:], file_path=gt_path, preprocess='gt', target_size=(224,224))\n",
    "vx_lg = load_images(img_names=val_meta.filename[120:], file_path=img_path, preprocess='image', target_size=(224,224,3))\n",
    "vy_lg = load_images(img_names=val_meta.filename[120:], file_path=gt_path, preprocess='gt', target_size=(224,224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get the small images for a dataset\n",
    "tx_full = load_images(img_names=train_meta.filename[0:], file_path=img_path, preprocess='image', target_size=(224,224,3))\n",
    "ty_full  = load_images(img_names=train_meta.filename[0:], file_path=gt_path, preprocess='gt', target_size=(224,224))\n",
    "vx_full = load_images(img_names=val_meta.filename[0:], file_path=img_path, preprocess='image', target_size=(224,224,3))\n",
    "vy_full = load_images(img_names=val_meta.filename[0:], file_path=gt_path, preprocess='gt', target_size=(224,224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_counts(filenames):\n",
    "    count = []\n",
    "    for f in filenames:\n",
    "        count.append(int(str.split(str.split(f, '_')[2], 'C')[1]))\n",
    "    return count\n",
    "train_counts_sm = get_counts(train_meta.filename[:480])\n",
    "val_counts_sm = get_counts(val_meta.filename[:120])\n",
    "train_counts_lg = get_counts(train_meta.filename[480:])\n",
    "val_counts_lg = get_counts(val_meta.filename[120:])\n",
    "train_counts_full = get_counts(train_meta.filename)\n",
    "val_counts_full = get_counts(val_meta.filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Normalize the small datasets\n",
    "avgs = per_chan_avg(tx_sm)\n",
    "normalize(tx_sm, avgs)\n",
    "normalize(vx_sm, avgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Normalize the large datasets\n",
    "avgs = per_chan_avg(tx_lg)\n",
    "normalize(tx_lg, avgs)\n",
    "normalize(vx_lg, avgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Normalize the full datasets\n",
    "avgs = per_chan_avg(tx_full)\n",
    "normalize(tx_full, avgs)\n",
    "normalize(vx_full, avgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_num = -1\n",
    "fig, a = plt.subplots(1, 6)\n",
    "a[0].imshow(tx_sm[im_num,:,:,2])\n",
    "a[1].imshow(ty_sm[im_num,:,:,0])\n",
    "a[2].imshow(tx_lg[im_num,:,:,2])\n",
    "a[3].imshow(ty_lg[im_num,:,:,0])\n",
    "a[4].imshow(tx_full[im_num,:,:,2])\n",
    "a[5].imshow(ty_full[im_num,:,:,0])\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(18.5, 10.5)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segmentation (Blob Detection) Network Comparison\n",
    "#### Train the network on the small cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fcn_sm = nn_models.build_fcn_bilinear_8s(nb_classes=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fcn_sm.load_weights('mod/fcn8s-bilinear_update_full_train-11-20-17.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NB_EPOCHS = 1000\n",
    "OPTIMIZER = Adam(lr=0.001)\n",
    "LOSS = binary_cross # Binary cross entropy\n",
    "VERBOSE = 1\n",
    "BATCH_SIZE = 1\n",
    "\n",
    "# Create a callback function to save the most accurate version of our model following each epoch, to stop if learning stops, and\n",
    "# to reduce the learning rate if loss fails to decrease.\n",
    "CALLBACKS = [ModelCheckpoint('mod/fcn8s_weights_sm.hdf5', monitor='loss', verbose=1, \n",
    "                           save_best_only=True, save_weights_only=False, mode='auto', period=1),\n",
    "            EarlyStopping(monitor='loss', min_delta=0, patience=15, verbose=0, mode='auto'),\n",
    "            ReduceLROnPlateau(monitor='loss', factor=0.1, patience=10, verbose=VERBOSE, mode='auto',\n",
    "                              epsilon=0.0001, cooldown=0, min_lr=0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fcn_sm.compile(loss=LOSS, optimizer=OPTIMIZER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sm_history = fcn_sm.fit(x=tx_sm,y=ty_sm, epochs=NB_EPOCHS, batch_size=BATCH_SIZE, verbose=VERBOSE, callbacks=CALLBACKS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fcn_sm = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the network on large cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fcn_lg = nn_models.build_fcn_bilinear_8s(nb_classes=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fcn_lg.load_weights('mod/fcn8s-bilinear_update_full_train-11-20-17.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NB_EPOCHS = 1000\n",
    "OPTIMIZER = Adam(lr=0.001)\n",
    "LOSS = binary_cross # Binary cross entropy\n",
    "VERBOSE = 1\n",
    "BATCH_SIZE = 1\n",
    "\n",
    "# Create a callback function to save the most accurate version of our model following each epoch, to stop if learning stops, and\n",
    "# to reduce the learning rate if loss fails to decrease.\n",
    "CALLBACKS = [ModelCheckpoint('mod/fcn8s_weights_lg.hdf5', monitor='loss', verbose=1, \n",
    "                           save_best_only=True, save_weights_only=False, mode='auto', period=1),\n",
    "            EarlyStopping(monitor='loss', min_delta=0, patience=15, verbose=0, mode='auto'),\n",
    "            ReduceLROnPlateau(monitor='loss', factor=0.1, patience=10, verbose=VERBOSE, mode='auto',\n",
    "                              epsilon=0.0001, cooldown=0, min_lr=0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fcn_lg.compile(loss=LOSS, optimizer=OPTIMIZER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lg_history = fcn_lg.fit(x=tx_lg,y=ty_lg, epochs=NB_EPOCHS, batch_size=BATCH_SIZE, verbose=VERBOSE, callbacks=CALLBACKS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fcn_lg = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the network on the full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fcn_full = nn_models.build_fcn_bilinear_8s(nb_classes=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fcn_full.load_weights('mod/fcn8s-bilinear_update_full_train-11-15-17.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NB_EPOCHS = 1000\n",
    "OPTIMIZER = Adam(lr=0.001)\n",
    "LOSS = binary_cross # Binary cross entropy\n",
    "VERBOSE = 1\n",
    "BATCH_SIZE = 1\n",
    "\n",
    "# Create a callback function to save the most accurate version of our model following each epoch, to stop if learning stops, and\n",
    "# to reduce the learning rate if loss fails to decrease.\n",
    "CALLBACKS = [ModelCheckpoint('mod/fcn8s_weights_full.hdf5', monitor='loss', verbose=1, \n",
    "                           save_best_only=True, save_weights_only=False, mode='auto', period=1),\n",
    "            EarlyStopping(monitor='loss', min_delta=0, patience=15, verbose=0, mode='auto'),\n",
    "            ReduceLROnPlateau(monitor='loss', factor=0.1, patience=10, verbose=VERBOSE, mode='auto',\n",
    "                              epsilon=0.0001, cooldown=0, min_lr=0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fcn_full.compile(loss=LOSS, optimizer=OPTIMIZER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "full_history = fcn_full.fit(x=tx_full,y=ty_full, epochs=NB_EPOCHS, batch_size=BATCH_SIZE, verbose=VERBOSE, callbacks=CALLBACKS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fcn_full = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Segmentation Results Comparison\n",
    "Results are evaluated through mean IoU comparison.  This will happen by first determining the optimial threshold for each set of data, and then determining the mean IoU for the data on which the network was trained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xRange = np.array(range(100), dtype=np.float32)\n",
    "xRange += 1\n",
    "xRange /= 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the small network optimal threshold\n",
    "fcn_sm = nn_models.build_fcn_bilinear_8s(nb_classes=1)\n",
    "fcn_sm.load_weights('mod/fcn8s_weights_sm.hdf5')\n",
    "sm_preds = fcn_sm.predict(vx_sm)\n",
    "meanIoU_by_thresh = metrics.meanIoU_thresholds(sm_preds, vy_sm)\n",
    "fig = plt.figure(figsize=(8, 6))\n",
    "plt.scatter(xRange, meanIoU_by_thresh)\n",
    "plt.title('Small Cell Dataset Mean IoU vs. Threshold Value')\n",
    "plt.ylabel('Mean IoU')\n",
    "plt.xlabel('Threshold')\n",
    "sm_thresh = xRange[np.argmax(meanIoU_by_thresh)]\n",
    "sm_meanIoU = np.amax(meanIoU_by_thresh)\n",
    "print('Max IoU',np.amax(meanIoU_by_thresh), 'Optimal IoU Threshold',xRange[np.argmax(meanIoU_by_thresh)])\n",
    "fcn_sm = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the large network optimal threshold\n",
    "fcn_lg = nn_models.build_fcn_bilinear_8s(nb_classes=1)\n",
    "fcn_lg.load_weights('mod/fcn8s_weights_lg.hdf5')\n",
    "lg_preds = fcn_lg.predict(vx_lg)\n",
    "meanIoU_by_thresh = metrics.meanIoU_thresholds(lg_preds, vy_lg)\n",
    "fig = plt.figure(figsize=(8, 6))\n",
    "plt.scatter(xRange, meanIoU_by_thresh)\n",
    "plt.title('Large Cell Dataset Mean IoU vs. Threshold Value')\n",
    "plt.ylabel('Mean IoU')\n",
    "plt.xlabel('Threshold')\n",
    "lg_thresh = xRange[np.argmax(meanIoU_by_thresh)]\n",
    "lg_meanIoU = np.amax(meanIoU_by_thresh)\n",
    "print('Max IoU',np.amax(meanIoU_by_thresh), 'Optimal IoU Threshold',xRange[np.argmax(meanIoU_by_thresh)])\n",
    "#fcn_lg = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the large network optimal threshold\n",
    "fcn_full = nn_models.build_fcn_bilinear_8s(nb_classes=1)\n",
    "fcn_full.load_weights('mod/fcn8s_weights_full.hdf5')\n",
    "full_preds = fcn_full.predict(vx_full)\n",
    "meanIoU_by_thresh = metrics.meanIoU_thresholds(full_preds, vy_full)\n",
    "fig = plt.figure(figsize=(8, 6))\n",
    "plt.scatter(xRange, meanIoU_by_thresh)\n",
    "plt.title('Full Cell Dataset Mean IoU vs. Threshold Value')\n",
    "plt.ylabel('Mean IoU')\n",
    "plt.xlabel('Threshold')\n",
    "full_thresh = xRange[np.argmax(meanIoU_by_thresh)]\n",
    "full_meanIoU = np.amax(meanIoU_by_thresh)\n",
    "print('Max IoU',np.amax(meanIoU_by_thresh), 'Optimal IoU Threshold',xRange[np.argmax(meanIoU_by_thresh)])\n",
    "fcn_full = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the Mean IoU for each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "meanIoUs = np.array((sm_meanIoU, lg_meanIoU, full_meanIoU))\n",
    "fig, ax = plt.subplots()\n",
    "ind = np.arange(1, 4)\n",
    "sm, lg, full = plt.bar((1, 2, 3), meanIoUs)\n",
    "plt.title('Mean Intersection Over Union')\n",
    "sm.set_facecolor('r')\n",
    "lg.set_facecolor('b')\n",
    "full.set_facecolor('rebeccapurple')\n",
    "ax.set_xticks(np.arange(1, 4))\n",
    "ax.set_xticklabels(['Small Cells', 'Large Cells', 'Combined\\nLarge/Small'])\n",
    "ax.set_ylim([0, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count Network Training and Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create 3 datasets\n",
    "1. The prediction image\n",
    "2. The predictions with a threshold applied\n",
    "3. The original image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# ID the high-performing model, and then train the counters\n",
    "if (sm_meanIoU > lg_meanIoU) and (sm_meanIoU > full_meanIoU):\n",
    "    fcn = nn_models.build_fcn_bilinear_8s(nb_classes=1)\n",
    "    fcn.load_weights('mod/fcn8s_weights_sm.hdf5')\n",
    "    seg_preds = fcn.predict(tx_sm)\n",
    "    im_preds = tx_sm\n",
    "    train_counts = train_counts_sm\n",
    "    val_counts = val_counts_sm\n",
    "    thresh = sm_thresh\n",
    "elif (lg_meanIoU > sm_meanIoU) and (lg_meanIoU > full_meanIoU):\n",
    "\n",
    "else:\n",
    "    fcn = nn_models.build_fcn_bilinear_8s(nb_classes=1)\n",
    "    fcn.load_weights('mod/fcn8s_weights_full.hdf5')\n",
    "    seg_preds = fcn.predict(tx_full)\n",
    "    im_preds = tx_full\n",
    "    train_counts = train_counts_full\n",
    "    val_counts = val_counts_full\n",
    "    thresh = full_thresh\n",
    "print('Threshold',thresh)\n",
    "plt.imshow(seg_preds[0:,:,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fcn = fcn_lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#fcn.load_weights('mod/fcn8s_weights_lg.hdf5')\n",
    "seg_preds = fcn.predict(tx_lg)\n",
    "im_preds = tx_lg\n",
    "train_counts = train_counts_lg\n",
    "val_counts = val_counts_lg\n",
    "thresh = lg_thresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seg_preds = np.concatenate((seg_preds, seg_preds, seg_preds), axis=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Apply threshold\n",
    "seg_preds = np.array((seg_preds > thresh) * 255, dtype=np.float32)\n",
    "avgs = per_chan_avg(arr=seg_preds)\n",
    "normalize(arr=seg_preds, avgs=avgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# No threshold\n",
    "seg_preds = fcn.predict(tx_lg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(seg_preds[22,:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tx_sm = None\n",
    "vx_sm = None\n",
    "tx_full = None\n",
    "vx_full = None\n",
    "ty_sm = None\n",
    "vy_full = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the segmentation counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seg_counter = nn_models.build_count_nn(nb_classes=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seg_counter.load_weights('mod/vgg_reg_11-20-17_full_train-W1imagesonly.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CALLBACKS = [ModelCheckpoint('mod/seg_counter.hdf5', monitor='mean_absolute_error', verbose=1, \n",
    "                           save_best_only=True, save_weights_only=True, mode='auto', period=1),\n",
    "            ReduceLROnPlateau(monitor='loss', factor=0.1, patience=10, verbose=1, mode='auto',\n",
    "                              epsilon=0.0001, cooldown=0, min_lr=0),\n",
    "            keras.callbacks.EarlyStopping(monitor='loss', min_delta=0, patience=30, verbose=0, mode='auto')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seg_counter.compile(optimizer='Adam',\n",
    "                     loss='mean_squared_error',\n",
    "                     metrics=['mean_absolute_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "seg_history = seg_counter.fit(seg_preds, train_counts,\n",
    "                          epochs=1000,\n",
    "                          batch_size=40,\n",
    "                          callbacks=CALLBACKS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seg_counter = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Segmentation Counter, no threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "seg_history = seg_counter.fit(seg_preds, train_counts,\n",
    "                          epochs=1000,\n",
    "                          batch_size=40,\n",
    "                          callbacks=CALLBACKS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seg_preds = fcn.predict(tx_lg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seg_preds = np.concatenate((seg_preds, seg_preds, seg_preds), axis=3)\n",
    "# Apply threshold\n",
    "seg_preds = np.array((seg_preds * 255), dtype=np.float32)\n",
    "avgs = per_chan_avg(arr=seg_preds)\n",
    "normalize(arr=seg_preds, avgs=avgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seg_counter_nt = nn_models.build_count_nn(nb_classes=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seg_counter_nt.load_weights('mod/seg_counter.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CALLBACKS = [ModelCheckpoint('mod/seg_counter_nt.hdf5', monitor='mean_absolute_error', verbose=1, \n",
    "                           save_best_only=True, save_weights_only=True, mode='auto', period=1),\n",
    "            ReduceLROnPlateau(monitor='loss', factor=0.1, patience=10, verbose=1, mode='auto',\n",
    "                              epsilon=0.0001, cooldown=0, min_lr=0),\n",
    "            keras.callbacks.EarlyStopping(monitor='loss', min_delta=0, patience=30, verbose=0, mode='auto')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seg_counter_nt.compile(optimizer='Adam',\n",
    "                     loss='mean_squared_error',\n",
    "                     metrics=['mean_absolute_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "seg_history_nt = seg_counter_nt.fit(seg_preds, train_counts,\n",
    "                          epochs=1000,\n",
    "                          batch_size=40,\n",
    "                          callbacks=CALLBACKS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the image Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_counter = nn_models.build_count_nn(nb_classes=1, copy_model=fcn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_counter.load_weights('mod/seg_counter.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CALLBACKS = [ModelCheckpoint('mod/img_counter.hdf5', monitor='mean_absolute_error', verbose=1, \n",
    "                           save_best_only=True, save_weights_only=True, mode='auto', period=1),\n",
    "            ReduceLROnPlateau(monitor='loss', factor=0.1, patience=10, verbose=1, mode='auto',\n",
    "                              epsilon=0.0001, cooldown=0, min_lr=0),\n",
    "            keras.callbacks.EarlyStopping(monitor='mean_absolute_error', min_delta=0, patience=30, verbose=0, mode='auto')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_counter.compile(optimizer='Adam',\n",
    "                     loss='mean_squared_error',\n",
    "                     metrics=['mean_absolute_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "img_history = img_counter.fit(im_preds, train_counts,\n",
    "                          epochs=1000,\n",
    "                          batch_size=40,\n",
    "                          callbacks=CALLBACKS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtain counts from the models and compare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start with the segmentation network counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seg_counter = nn_models.build_count_nn(nb_classes=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seg_counter.load_weights('mod/seg_counter.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seg_vx_lg = fcn.predict(vx_lg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seg_vx_lg = np.concatenate((seg_vx_lg,seg_vx_lg,seg_vx_lg), axis=3)\n",
    "# Apply threshold\n",
    "seg_vx_lg = np.array((seg_vx_lg > thresh) * 255, dtype=np.float32)\n",
    "avgs = per_chan_avg(arr=seg_vx_lg)\n",
    "normalize(arr=seg_vx_lg, avgs=avgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seg_vx_counts = seg_counter.predict(seg_vx_lg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seg_dat = pd.DataFrame({'Count': val_counts,\n",
    "                   'Pred': seg_vx_counts[:,0]})\n",
    "#Group the data by count\n",
    "seg_grouped = seg_dat.groupby('Count')\n",
    "seg_dat_1sig = seg_grouped.std()\n",
    "seg_dat_2sig = seg_dat_1sig * 2\n",
    "seg_dat_mean = seg_grouped.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_dat.to_csv('data/segmented_counts.csv')\n",
    "seg_grouped.to_csv('data/segmented_counts_grouped.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Segmentation counting without threshold\n",
    "Test the count of the segmentation without threshold results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seg_nt_vx_lg = fcn.predict(vx_lg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seg_nt_vx_lg = np.concatenate((seg_nt_vx_lg,seg_nt_vx_lg,seg_nt_vx_lg), axis=3)\n",
    "# Apply threshold\n",
    "seg_nt_vx_lg = np.array((seg_nt_vx_lg > thresh) * 255, dtype=np.float32)\n",
    "avgs = per_chan_avg(arr=seg_nt_vx_lg)\n",
    "normalize(arr=seg_nt_vx_lg, avgs=avgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seg_nt_vx_counts = seg_counter_nt.predict(seg_nt_vx_lg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seg_nt_dat = pd.DataFrame({'Count': val_counts,\n",
    "                   'Pred': seg_nt_vx_counts[:,0]})\n",
    "#Group the data by count\n",
    "seg_nt_grouped = seg_nt_dat.groupby('Count')\n",
    "seg_nt_dat_1sig = seg_nt_grouped.std()\n",
    "seg_nt_dat_2sig = seg_nt_dat_1sig * 2\n",
    "seg_nt_dat_mean = seg_nt_grouped.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seg_nt_dat.to_csv('data/segmented_nt_counts.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### No segmentation, image only\n",
    "Move on to the image network counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_counter = nn_models.build_count_nn(nb_classes=1)\n",
    "img_counter.load_weights('mod/img_counter.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_vx_counts = img_counter.predict(vx_lg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_dat = pd.DataFrame({'Count': val_counts,\n",
    "                   'Pred': img_vx_counts[:,0]})\n",
    "#Group the data by count\n",
    "img_grouped = img_dat.groupby('Count')\n",
    "img_dat_1sig = img_grouped.std()\n",
    "img_dat_2sig = img_dat_1sig * 2\n",
    "img_dat_mean = img_grouped.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_dat.to_csv('data/img_counts.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform the Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def scatter_with_deviation(val_counts, reg_val_preds, grouped, title):\n",
    "    plt.figure(figsize=(8,5))\n",
    "    plt.scatter(val_counts, reg_val_preds, marker=\".\")\n",
    "    plt.plot(grouped.mean())\n",
    "    plt.plot((np.array(range(100)) + 1))\n",
    "    '''\n",
    "    plt.fill_between(dat_mean.index,\n",
    "                     (dat_mean - dat_1sig)['Pred'].values,\n",
    "                     (dat_mean + dat_1sig)['Pred'].values,\n",
    "                     alpha=0.5)\n",
    "    plt.fill_between(dat_mean.index,\n",
    "                     (dat_mean - 2 * dat_1sig)['Pred'].values,\n",
    "                     (dat_mean + 2 * dat_1sig)['Pred'].values,\n",
    "                     alpha=0.2)\n",
    "                     '''\n",
    "    plt.ylabel('Prediction')\n",
    "    plt.xlabel('Cell Count')\n",
    "    plt.title(title)\n",
    "    #plt.semilogy()\n",
    "    #plt.plot(grouped.mean() + grouped.std())\n",
    "    #plt.plot(grouped.mean() - grouped.std())\n",
    "    #plt.plot(grouped.mean() + 2*grouped.std())\n",
    "    #plt.plot(grouped.mean() - 2*grouped.std())\n",
    "    #plt.savefig('PredsVsCounts.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter_with_deviation(val_counts, seg_vx_counts, seg_grouped, 'Predictions from Segmented Image w/Threshold vs. Actual Counts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scatter_with_deviation(val_counts, seg_vx_counts, seg_grouped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter_with_deviation(val_counts, img_vx_counts, img_grouped,'Predictions from Original Images vs. Actual Counts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter_with_deviation(val_counts, seg_nt_vx_counts, seg_nt_grouped, 'Predictions from Segmented Image w/o Threshold vs. Actual Counts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_nt_grouped.std().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seg_nt_gp = pd.DataFrame(seg_nt_grouped.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(seg_nt_gp.index, seg_nt_grouped.std())\n",
    "plt.scatter(seg_nt_gp.index, seg_grouped.std())\n",
    "plt.scatter(seg_nt_gp.index, img_grouped.std())\n",
    "plt.title('Prediction Standard Deviations vs. Actual Counts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = seg_nt_grouped['Count'].all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = x.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Three subplots sharing both x/y axes\n",
    "f, (ax1, ax2, ax3) = plt.subplots(3, sharex=True, sharey=True)\n",
    "ax1.plot(seg_nt_gp.index, seg_nt_grouped.std())\n",
    "ax1.set_title('Standard Deviation vs. Cell Count')\n",
    "ax2.plot(seg_nt_gp.index, seg_grouped.std())\n",
    "ax3.plot(seg_nt_gp.index, img_grouped.std(), color='r')\n",
    "# Fine-tune figure; make subplots close to each other and hide x ticks for\n",
    "# all but bottom plot.\n",
    "f.subplots_adjust(hspace=0)\n",
    "plt.setp([a.get_xticklabels() for a in f.axes[:-1]], visible=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
